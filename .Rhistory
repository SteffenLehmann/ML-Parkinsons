library(ggplot2)
library(factoextra)
data <- read.table("parkinsons.data", header=TRUE, sep=",")
healthy_label <- "1"
parkinsons_label <- "0"
Healthy <- data %>% filter(status==healthy_label)
Parkinsons <- data %>% filter(status==parkinsons_label)
Overview <- skim(data)
Overview_Healthy <- skim(Healthy)
Overview_Parkinsons <- skim(Parkinsons)
View(Overview)
View(data)
View(Overview)
View(Overview)
sort()?
?sort()
View(data)
PPData <- data %>% select(-one_of('name', 'status'))
View(PPData)
#Removing the labels from the data set. In this case it is the name and status
PPData <- data %>% select(-one_of('name', 'status'))
LabelDF <- data %>% select(one_of('name', 'status'))
View(LabelDF)
#Removing the labels from the data set. In this case it is the name and status
#TODO might not need to remove name
PPData <- data %>% select(-one_of('name', 'status'))
#Selecting the labels so they can be added again later to check the ML
LabelDF <- data %>% select(one_of('name', 'status'))
import numpy as np
install pandas
reticulate::repl_python()
quit
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
library(ggplot2)
library(tidyverse)
library(tidymodels)
library(skimr)
library(stringr)
library(corrplot)
library(RColorBrewer)
library("PerformanceAnalytics")
library("Hmisc")
library(Rmisc)
library(lubridate)
library(ggbeeswarm)
library(GGally)
library(effsize)
library(magrittr)
library(dplyr)
library(reticulate)
flattenCorrMatrix <- function(cormat, pmat) {
ut <- upper.tri(cormat)
data.frame(
row = rownames(cormat)[row(cormat)[ut]],
column = rownames(cormat)[col(cormat)[ut]],
cor  =(cormat)[ut],
p = pmat[ut]
)
}
reticulate::repl_python()
import matplotlib.pyplot as plt
from scipy import stats as sc
import pandas as pd
#py_dfSummary = r.dfSummary
#x = py_dfSummary["EDA"]
#y = py_dfSummary["IBI"]
#plt.scatter(x, y)
#plt.show()
py_dsSummary = r.dsSummary
x2 = py_dsSummary["RightControllerPosWorldX"]
y2 = py_dsSummary["RightControllerPosWorldY"]
users = py_dsSummary["Participant"]
plt.scatter(x2, y2)
plt.show()
slope, intercept, p, r2, std_err = sc.linregress(x2, y2)
def lr(x2):
return slope * x2 + intercept
mymodel = list(map(lr, x2))
p_df = pd.DataFrame(x2, y2, users)
fig, ax = plt.subplots()
bp = p_df.groupby("users").plot(kind="kde", ax=ax)
plt.scatter(x2, y2)
plt.plot(x2, mymodel)
plt.show()
pip install package
pip install package("pandas")
quit
reticulate::repl_python()
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
pip install package(pandas)
pip install package('pandas')
Pip install pandas
Pip install pandas
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
X = data.drop(columns=['name','status'], axis=1)
Y = data['status']
quit
library(Rmisc) # summarySE
library(MASS) # polr
library(tidyverse)
library(tidymodels)
library(skimr)
library(lubridate)  # for handling dates and time
library(Hmisc)    # correlation
library(corrplot)
library(PerformanceAnalytics)
library(RColorBrewer)
library(GGally)
library(psych) # ICC
library(ggbeeswarm)
library(dplyr)
library(ggplot2)
library(factoextra)
data <- read.table("parkinsons.data", header=TRUE, sep=",")
healthy_label <- "1"
parkinsons_label <- "0"
Healthy <- data %>% filter(status==healthy_label)
Parkinsons <- data %>% filter(status==parkinsons_label)
#I am looking at the distribution of the data and within each label. This also check the data for empty cells
Overview <- skim(data)
Overview_Healthy <- skim(Healthy)
Overview_Parkinsons <- skim(Parkinsons)
#Removing the labels from the data set. In this case it is the name and status
#TODO might not need to remove name
PPData <- data %>% select(-one_of('name', 'status'))
#Selecting the labels so they can be added again later to check the ML
LabelDF <- data %>% select(one_of('name', 'status'))
reticulate::repl_python()
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
X = data.drop(columns=['name','status'], axis=1)
Y = data['status']
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
r.data = py.data
X = data.drop(columns=['name','status'], axis=1)
Y = data['status']
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
r.data = py_data
X = py_data.drop(columns=['name','status'], axis=1)
Y = py_data['status']
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
py_data = r.data
X = py_data.drop(columns=['name','status'], axis=1)
Y = py_data['status']
X
Y
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#dropping / removing the labels from the data frame
X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
Y = py_data['status']
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#dropping / removing the labels from the data frame
X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
Y = py_data['status']
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
quit
#Removing the labels from the data set. In this case it is the name and status
#TODO might not need to remove name
PPData <- data %>% select(-one_of('name', 'status'))
#Selecting the labels so they can be added again later to check the ML
LabelDF <- data %>% select(one_of('name', 'status'))
reticulate::repl_python()
View(X_train)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#dropping / removing the labels from the data frame
X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#scaling / normalizing the data
scaler = StandardScaler()
scaler.fit(py_data)
#dropping / removing the labels from the data frame
X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
View(py_data)
View(scaler)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#scaling / normalizing the data
scaler = StandardScaler()
Nor_data = scaler.fit(py_data)
#dropping / removing the labels from the data frame
X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#scaling / normalizing the data
scaler = StandardScaler()
Nor_data = scaler.fit(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#scaling / normalizing the data
scaler = StandardScaler()
Nor_data = scaler.fit(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#scaling / normalizing the data
scaler = StandardScaler()
scaler.fit(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
View(py_data)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#scaling / normalizing the data
scaler = StandardScaler()
scaler.fit(py_data)
StandardScaler()
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#scaling / normalizing the data
scaler = StandardScaler()
scaler.fit(py_data)
Scal_data = scaler.transform(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#scaling / normalizing the data
scaler = StandardScaler()
Scal_data = scaler.fit_transform(py_data)
# = scaler.transform(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
View(py_data)
quit
#Removing the labels from the data set. In this case it is the name and status
#TODO might not need to remove name
PPData <- data %>% select(-one_of('name'))
#Selecting the labels so they can be added again later to check the ML
LabelDF <- data %>% select(one_of('name', 'status'))
View(PPData)
#Removing the labels from the data set. In this case it is the name and status
#TODO might not need to remove name
PPData <- data %>% select(-one_of('name'))
#Selecting the labels so they can be added again later to check the ML
LabelDF <- data %>% select(one_of('name', 'status'))
reticulate::repl_python()
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.PPData
#scaling / normalizing the data
scaler = StandardScaler()
Scal_data = scaler.fit_transform(py_data)
# = scaler.transform(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
View(Scal_data)
View(py_data)
View(Scal_data)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.PPData
#scaling / normalizing the data
scaler = StandardScaler()
Scal_data = scaler.fit(py_data)
# = scaler.transform(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
View(Scal_data)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.PPData
#scaling / normalizing the data
scaler = StandardScaler()
scaler.fit(py_data)
Scal_data = scaler.transform(py_data)
# = scaler.transform(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
View(Scal_data)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.PPData
#scaling / normalizing the data
scaler = StandardScaler()
scaler.fit(py_data)
scaler.transform(py_data)
# = scaler.transform(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
View(Scal_data)
View(py_data)
View(scaler)
View(Scal_data)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.PPData
#scaling / normalizing the data
scaler = StandardScaler()
scaler.fit(py_data)
scaled_data = scaler.transform(py_data)
# = scaler.transform(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.PPData
#scaling / normalizing the data
scaler = StandardScaler()
scaler.fit(py_data)
scaled_data = scaler.transform(py_data)
#dropping / removing the labels from the data frame
X = scaled_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
