#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#scaling / normalizing the data
scaler = StandardScaler()
scaler.fit(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
View(py_data)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#scaling / normalizing the data
scaler = StandardScaler()
scaler.fit(py_data)
StandardScaler()
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#scaling / normalizing the data
scaler = StandardScaler()
scaler.fit(py_data)
Scal_data = scaler.transform(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#scaling / normalizing the data
scaler = StandardScaler()
Scal_data = scaler.fit_transform(py_data)
# = scaler.transform(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
View(py_data)
quit
#Removing the labels from the data set. In this case it is the name and status
#TODO might not need to remove name
PPData <- data %>% select(-one_of('name'))
#Selecting the labels so they can be added again later to check the ML
LabelDF <- data %>% select(one_of('name', 'status'))
View(PPData)
#Removing the labels from the data set. In this case it is the name and status
#TODO might not need to remove name
PPData <- data %>% select(-one_of('name'))
#Selecting the labels so they can be added again later to check the ML
LabelDF <- data %>% select(one_of('name', 'status'))
reticulate::repl_python()
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.PPData
#scaling / normalizing the data
scaler = StandardScaler()
Scal_data = scaler.fit_transform(py_data)
# = scaler.transform(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
View(Scal_data)
View(py_data)
View(Scal_data)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.PPData
#scaling / normalizing the data
scaler = StandardScaler()
Scal_data = scaler.fit(py_data)
# = scaler.transform(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
View(Scal_data)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.PPData
#scaling / normalizing the data
scaler = StandardScaler()
scaler.fit(py_data)
Scal_data = scaler.transform(py_data)
# = scaler.transform(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
View(Scal_data)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.PPData
#scaling / normalizing the data
scaler = StandardScaler()
scaler.fit(py_data)
scaler.transform(py_data)
# = scaler.transform(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
View(Scal_data)
View(py_data)
View(scaler)
View(Scal_data)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.PPData
#scaling / normalizing the data
scaler = StandardScaler()
scaler.fit(py_data)
scaled_data = scaler.transform(py_data)
# = scaler.transform(py_data)
#dropping / removing the labels from the data frame
#X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.PPData
#scaling / normalizing the data
scaler = StandardScaler()
scaler.fit(py_data)
scaled_data = scaler.transform(py_data)
#dropping / removing the labels from the data frame
X = scaled_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
#Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
library(Rmisc) # summarySE
library(MASS) # polr
library(tidyverse)
library(tidymodels)
library(skimr)
library(lubridate)  # for handling dates and time
library(Hmisc)    # correlation
library(corrplot)
library(PerformanceAnalytics)
library(RColorBrewer)
library(GGally)
library(psych) # ICC
library(ggbeeswarm)
library(dplyr)
library(ggplot2)
library(factoextra)
data <- read.table("parkinsons.data", header=TRUE, sep=",")
#I am looking at the distribution of the data and within each label. This also check the data for empty cells
Overview <- skim(data)
Overview_Healthy <- skim(Healthy)
Overview_Parkinsons <- skim(Parkinsons)
#Removing the labels from the data set. In this case it is the name and status
#TODO might not need to remove name
PPData <- data %>% select(-one_of('name'))
#Selecting the labels so they can be added again later to check the ML
LabelDF <- data %>% select(one_of('name', 'status'))
reticulate::repl_python()
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.PPData
#dropping / removing the labels from the data frame
X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
#converting the data frame from R to Python
py_data = r.data
#dropping / removing the labels from the data frame
X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
#converting the data frame from R to Python
py_data = r.data
#dropping / removing the labels from the data frame
X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
quit
library(Rmisc) # summarySE
library(MASS) # polr
library(tidyverse)
library(tidymodels)
library(skimr)
library(lubridate)  # for handling dates and time
library(Hmisc)    # correlation
library(corrplot)
library(PerformanceAnalytics)
library(RColorBrewer)
library(GGally)
library(psych) # ICC
library(ggbeeswarm)
library(dplyr)
library(ggplot2)
library(factoextra)
reticulate::repl_python()
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
quit
data <- read.table("parkinsons.data", header=TRUE, sep=",")
#I am looking at the distribution of the data and within each label. This also check the data for empty cells
Overview <- skim(data)
Overview_Healthy <- skim(Healthy)
Overview_Parkinsons <- skim(Parkinsons)
#Removing the labels from the data set. In this case it is the name and status
#TODO might not need to remove name
PPData <- data %>% select(-one_of('name', 'status'))
#Selecting the labels so they can be added again later to check the ML
LabelDF <- data %>% select(one_of('name', 'status'))
reticulate::repl_python()
#converting the data frame from R to Python
py_data = r.data
#dropping / removing the labels from the data frame
X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
#converting the data frame from R to Python
py_data = r.data
#dropping / removing the labels from the data frame
X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
#Scaling the data
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
#converting the data frame from R to Python
py_data = r.data
#dropping / removing the labels from the data frame
X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
#Scaling the data
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
#converting the data frame from R to Python
py_data = r.data
#dropping / removing the labels from the data frame
X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
#Scaling the data
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
#converting the data frame from R to Python
py_data = r.data
#dropping / removing the labels from the data frame
X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
#Scaling the data
scaler = StandardScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
#Scaling the data.
SVM_model = svm.SVC(kernel='linear')
SVM_model.fit(X_train_scaled, Y_train)
#Scaling the data.
SVM_model = svm.SVC(kernel='linear')
SVM_model.fit(X_train_scaled, Y_train)
# Calculating the accuracy score in percent
trained_X_data = model.predict(X_train_scaled)
Accuracy_on_train_data = accuracy_score(Y_train, trained_X_data)
quit
library(Rmisc) # summarySE
library(MASS) # polr
library(tidyverse)
library(tidymodels)
library(skimr)
library(lubridate)  # for handling dates and time
library(Hmisc)    # correlation
library(corrplot)
library(PerformanceAnalytics)
library(RColorBrewer)
library(GGally)
library(psych) # ICC
library(ggbeeswarm)
library(dplyr)
library(ggplot2)
library(factoextra)
reticulate::repl_python()
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
quit
data <- read.table("parkinsons.data", header=TRUE, sep=",")
#I am looking at the distribution of the data and within each label. This also check the data for empty cells
Overview <- skim(data)
Overview_Healthy <- skim(Healthy)
Overview_Parkinsons <- skim(Parkinsons)
#Removing the labels from the data set. In this case it is the name and status
#TODO might not need to remove name
PPData <- data %>% select(-one_of('name', 'status'))
#Selecting the labels so they can be added again later to check the ML
LabelDF <- data %>% select(one_of('name', 'status'))
reticulate::repl_python()
#converting the data frame from R to Python
py_data = r.data
#22 features
#dropping / removing the labels from the data frame
X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
#Scaling the data.
#https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html?highlight=standardscaler#sklearn.preprocessing.StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
#Training the Support Vector classifier
SVM_model = svm.SVC(kernel='linear')
SVM_model.fit(X_train_scaled, Y_train)
# Calculating the accuracy score in percent
trained_X_data = model.predict(X_train_scaled)
Accuracy_on_train_data = accuracy_score(Y_train, trained_X_data)
# Calculating the accuracy score in percent
trained_X_data = SVM_model.fit.predict(X_train_scaled)
Accuracy_on_train_data = accuracy_score(Y_train, trained_X_data)
# Calculating the accuracy score in percent
trained_X_data = SVM_model.predict(X_train_scaled)
Accuracy_on_train_data = accuracy_score(Y_train, trained_X_data)
View(Accuracy_on_train_data)
# Calculating the accuracy score in percent on training data
trained_X_data = SVM_model.predict(X_train_scaled)
Accuracy_on_train_data = accuracy_score(Y_train, trained_X_data)
# Calculating the accuracy score in percent on test data
test_X_data = SVM_model.predict(X_test_scaled)
Accuracy_on_test_data = accuracy_score(Y_test, test_X_data)
library(Rmisc) # summarySE
library(MASS) # polr
library(tidyverse)
library(tidymodels)
library(skimr)
library(lubridate)  # for handling dates and time
library(Hmisc)    # correlation
library(corrplot)
library(PerformanceAnalytics)
library(RColorBrewer)
library(GGally)
library(psych) # ICC
library(ggbeeswarm)
library(dplyr)
library(ggplot2)
library(factoextra)
reticulate::repl_python()
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
quit
data <- read.table("parkinsons.data", header=TRUE, sep=",")
healthy_label <- "1"
parkinsons_label <- "0"
Healthy <- data %>% filter(status==healthy_label)
Parkinsons <- data %>% filter(status==parkinsons_label)
#I am looking at the distribution of the data and within each label. This also check the data for empty cells
Overview <- skim(data)
Overview_Healthy <- skim(Healthy)
Overview_Parkinsons <- skim(Parkinsons)
#Removing the labels from the data set. In this case it is the name and status
#TODO might not need to remove name
PPData <- data %>% select(-one_of('name', 'status'))
#Selecting the labels so they can be added again later to check the ML
LabelDF <- data %>% select(one_of('name', 'status'))
reticulate::repl_python()
#converting the data frame from R to Python
py_data = r.data
#22 features
#dropping / removing the labels from the data frame
X = py_data.drop(columns=['name','status'], axis=1)
#data frame that is only containing the label
Y = py_data['status']
#splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting
#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
#Scaling the data.
#https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html?highlight=standardscaler#sklearn.preprocessing.StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
#Training the Support Vector classifier
SVM_model = svm.SVC(kernel='linear')
SVM_model.fit(X_train_scaled, Y_train)
# Calculating the accuracy score in percent on training data
trained_X_data = SVM_model.predict(X_train_scaled)
Accuracy_on_train_data = accuracy_score(Y_train, trained_X_data)
# Calculating the accuracy score in percent on test data
test_X_data = SVM_model.predict(X_test_scaled)
Accuracy_on_test_data = accuracy_score(Y_test, test_X_data)
