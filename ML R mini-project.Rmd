---
title: "R Notebook"
output: html_notebook
---

```{r Load packages, include=FALSE}
library(Rmisc) # summarySE
library(MASS) # polr
library(tidyverse)
library(tidymodels)
library(skimr)
library(lubridate)  # for handling dates and time
library(Hmisc)    # correlation
library(corrplot)
library(PerformanceAnalytics)
library(RColorBrewer)
library(GGally)
library(psych) # ICC
library(ggbeeswarm)
library(dplyr)
library(ggplot2)
library(reticulate) # for python
library(factoextra)
```

```{python Loading packages, include=FALSE}
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
from sklearn.decomposition import PCA,TruncatedSVD
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier

```

```{r load data, include=FALSE}
data <- read.table("parkinsons.data", header=TRUE, sep=",")
```

```{r Parittion data, include=FALSE}
healthy_label <- "1"
parkinsons_label <- "0"
Healthy <- data %>% filter(status==healthy_label)
Parkinsons <- data %>% filter(status==parkinsons_label)
```

```{r Quick overview}
#I am looking at the distribution of the data and within each label. This also check the data for empty cells 
Overview <- skim(data)
Overview_Healthy <- skim(Healthy)
Overview_Parkinsons <- skim(Parkinsons)

```


```{r Pre-processing in R}
#Removing the labels from the data set. In this case it is the name and status
#TODO might not need to remove name
PPData <- data %>% select(-one_of('name', 'status'))
#Selecting the labels so they can be added again later to check the ML
LabelDF <- data %>% select(one_of('name', 'status')) 

```


```{python Pre-processing in Python}
#converting the data frame from R to Python
py_data = r.data
#22 features
#Pre-processing
#   dropping / removing the labels from the data frame 
X = py_data.drop(columns=['name','status'], axis=1)
#   data frame that is only containing the label
Y = py_data['status']


#   splits the data into a test and training test, with 80% of the data being used for training. Shuffles the data twice before spiting 
#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

#Scaling the data. 
#https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html?highlight=standardscaler#sklearn.preprocessing.StandardScaler 

scaler = StandardScaler()
#Only fit on the training set
scaler.fit(X_train)
#Transform both sets
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

```
```{python PCA plot of the data in Python}
#pca with two principal components
pca = PCA(n_components=2)
principalComponents = pca.fit_transform(X)
#first principal component contains 72.89% of the variance and the second principal component contains 21.82% of the variance.
PCA_variance_n2 = pca.explained_variance_ratio_
principalDf = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2'])

#Concatenating DataFrames
plotDf = pd.concat([principalDf, Y], axis = 1)

#Scaling the data. 

scaler = StandardScaler()
scaler.fit(plotDf)
X_PCA_scaled = scaler.transform(plotDf)
```

```{r plotting 2D data}
PCA2 <- py$plotDf
scal_PCA2 <- py$X_PCA_scaled

scal_PCA2Df <- as.data.frame(scal_PCA2)
# Scatter plot of PCA(n=2)
ggplot(PCA2, aes(x=PC1, y=PC2, colour=status)) + geom_point() + stat_ellipse()
# Shows scatter of scaled dataPCA(n=2)
ggplot(scal_PCA2Df, aes(x=V1, y=V2, colour=V3)) + geom_point()

# Show the contour only PCA(n=2)
ggplot(PCA2, aes(x=PC1, y=PC2, colour=status)) + geom_point() + geom_density_2d()

# Show the area only PCA(n=2)
ggplot(PCA2, aes(x=PC1, y=PC2, colour=status)) + geom_point() + stat_density_2d(aes(fill = ..level..), geom="polygon")
# shows area + contour
ggplot(PCA2, aes(x=PC1, y=PC2, colour=status)) + geom_point() + stat_density_2d(aes(fill = ..level..), geom="polygon", colour="white")
```
```{python PCA pipeline in Python}
# 0.95 are the components parameter. It means that scikit-learn choose the minimum number of principal components such that 95% of the variance is retained.
PCA_SVC = PCA(.95)
PCA_SVC.fit(X_train_scaled)
#Number of PC's with 95% variance.
Number_of_PC = PCA_SVC.n_components_
#Apply the PCA fit
PCA_train = PCA_SVC.transform(X_train_scaled)
PCA_test = PCA_SVC.transform(X_test_scaled)
```

```{python SVC in Python}
#Training the Support Vector classifier 
SVM_model = svm.SVC(kernel='linear')
SVM_model.fit(X_train_scaled, Y_train)

# Calculating the accuracy score in percent on training data
trained_X_data = SVM_model.predict(X_train_scaled)
Accuracy_SVC_train = accuracy_score(Y_train, trained_X_data) 
# Calculating the accuracy score in percent on test data
test_X_data = SVM_model.predict(X_test_scaled)
Accuracy_SVC_test = accuracy_score(Y_test, test_X_data)
# Fit values
Fit_SVC = Accuracy_SVC_train-Accuracy_SVC_test

```

```{python PCA and SVC in Python}
#Training the Support Vector classifier 
SVM_PCA_model = svm.SVC(kernel='linear')
SVM_PCA_model.fit(PCA_train, Y_train)


# Calculating the accuracy score in percent on training data
SVM_PCA_train =SVM_PCA_model.predict(PCA_train)
Accuracy_SVM_PCA_train = accuracy_score(Y_train, SVM_PCA_train) 
# Calculating the accuracy score in percent on test data
SVM_PCA_test = SVM_PCA_model.predict(PCA_test)
Accuracy_SVM_PCA_test = accuracy_score(Y_test, SVM_PCA_test)
# Fit values
Fit_SVC_PCA = Accuracy_SVM_PCA_train-Accuracy_SVM_PCA_test

```

```{python RandomForestClassifier in Python}
#TODO model is over fitted, so the attributes of the model needs to be designed better
rf_Model = RandomForestClassifier()
rf_Model.fit(X_train_scaled, Y_train)

RFC_Train =rf_Model.predict(X_train_scaled)
Accuracy_RFC_Train = accuracy_score(Y_train, RFC_Train)

RFC_Test =rf_Model.predict(X_test_scaled)
Accuracy_RFC_Test = accuracy_score(Y_test, RFC_Test)

Fit_RFC=Accuracy_RFC_Train-Accuracy_RFC_Test

#With PCA
rf_PCA_Model = RandomForestClassifier()
rf_PCA_Model.fit(PCA_train, Y_train)


RFC_PCA_Train =rf_PCA_Model.predict(PCA_train)
Accuracy_RFC_PCA_Train = accuracy_score(Y_train, RFC_PCA_Train)

RFC_PCA_Test =rf_PCA_Model.predict(PCA_test)
Accuracy_RFC_PCA_Test = accuracy_score(Y_test, RFC_PCA_Test)

Fit_RFC_PCA=Accuracy_RFC_PCA_Train-Accuracy_RFC_PCA_Test
```

```{python Neural Network in Python}
NN = MLPClassifier(activation = 'logistic', solver = 'sgd', hidden_layer_sizes=(100), random_state=1, max_iter=3000)
NN.fit(X_train_scaled, Y_train)
NN_Predict = NN.predict(X_test_scaled)
Accuracy_NN = NN.score(X_test_scaled, Y_test)

NN_PCA = MLPClassifier(activation = 'logistic', solver = 'sgd', hidden_layer_sizes=(100), random_state=1, max_iter=3000)
NN_PCA.fit(PCA_train, Y_train)
NN_Predict_PCA = NN_PCA.predict(PCA_test)
Accuracy_NN_PCA = NN_PCA.score(PCA_test, Y_test)

Fit_NN=Accuracy_NN-Accuracy_NN_PCA
```

```{python Naive Bayes in Python}


```


```{python Model evaluation in Python}
Models = [SVM_model, rf_Model, NN]
Model_name = [Support Vector Classifier, Neural network]

for x in Models:
  x.score(X_test_scaled, Y_test)

```